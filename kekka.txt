使用デバイス: cpu

--- [フェーズ1 開始] ---
全データ読み込み完了: 148517 件
既知のデータセットサイズ: 140981 件
未知のデータセットサイズ: 7536 件

--- [フェーズ1 完了] ---

--- [フェーズ2 開始] ---
ステップ 2.1: ラベルをカテゴリに変換中...

既知データセットのカテゴリ分布 (処理前):
attack_category
DoS       52458
Normal    77054
Probe      8771
R2L        2584
U2R         114
Name: count, dtype: int64
ラベルを 5 個の数値にエンコードしました。
カテゴリ名: ['DoS' 'Normal' 'Probe' 'R2L' 'U2R']
対応する数値: [0 1 2 3 4]

ステップ 2.2: 特徴量のエンコーディングと標準化...
既知のデータ (X_known) を使って前処理パイプラインを学習 (fit)...
学習したパイプラインで X_known と X_unknown を変換 (transform)...
前処理後の既知データの形状 (行, 列): (140981, 122)
前処理後の未知データの形状 (行, 列): (7536, 122)

--- [フェーズ2 (サンプリング前処理) 完了] ---

--- [フェーズ3 開始 (DAEモデルの学習)] ---
dae_model.pth が見つかりません。DAEの学習を開始します...

DAE学習開始 (デバイス: cpu)
DAE学習データ形状: (140981, 122) (SMOTE適用前)
エポック [1/300], 損失 (Loss): 0.152246
エポック [50/300], 損失 (Loss): 0.004322
エポック [100/300], 損失 (Loss): 0.003377
エポック [150/300], 損失 (Loss): 0.002881
エポック [200/300], 損失 (Loss): 0.002678
エポック [250/300], 損失 (Loss): 0.002652
エポック [300/300], 損失 (Loss): 0.002435
DAE学習完了。
学習完了。モデルを dae_model.pth に保存します。

--- [フェーズ3 完了 (DAEモデル準備OK)] ---

--- [フェーズ4 開始 (特徴量抽出 & DDQN学習)] ---
DAEエンコーダで「既知データ」の特徴量を抽出中...
  DAE特徴量 形状: (140981, 64)

ステップ 4.1: DAE特徴量のサンプリング (SMOTE + ENN) を実行中...
サンプリング前のデータ形状: (140981, 64)
サンプリング前のラベル分布 (数値):
0    52458
1    77054
2     8771
3     2584
4      114
Name: count, dtype: int64
ENN (アンダーサンプリング) を有効にして実行します。(時間がかかります)

サンプリング後のデータ形式: <class 'numpy.ndarray'>
サンプリング後のデータ形状: (382502, 64)
サンプリング後のラベル分布 (数値):
0    76923
1    75560
2    76938
3    76101
4    76980
Name: count, dtype: int64

ステップ 4.2: DDQNモデルの学習...
ddqn_model.pth が見つかりません。DDQNの学習を開始します...
DDQN学習のため、サンプリング後の既知データをシャッフル中...

DDQN学習開始 (デバイス: cpu)
DDQN試行 [1/10], 損失 (Loss): 0.046830
DDQN試行 [2/10], 損失 (Loss): 0.030149
DDQN試行 [3/10], 損失 (Loss): 0.021276
DDQN試行 [4/10], 損失 (Loss): 0.018737
DDQN試行 [5/10], 損失 (Loss): 0.016693
DDQN試行 [6/10], 損失 (Loss): 0.015011
DDQN試行 [7/10], 損失 (Loss): 0.013695
DDQN試行 [8/10], 損失 (Loss): 0.013196
DDQN試行 [9/10], 損失 (Loss): 0.011860
DDQN試行 [10/10], 損失 (Loss): 0.011119
DDQN学習完了。
学習完了。モデルを ddqn_model.pth に保存します。

--- [フェーズ4 完了 (DDQNモデル準備OK)] ---

--- [フェーズ5 開始 (提案手法 DAE+DDQN の予測と評価)] ---

--- 提案手法 (DAE+DDQN) の予測性能 ---

マイクロ平均 (正解率): 70.25%
 (論文 [表6] "提案手法(DAE+DDQN)": 0.657)

カテゴリ別 適合率 (Precision), 再現率 (Recall), F値:
              precision    recall  f1-score   support

         DoS      0.959     0.973     0.966       929
      Normal      0.000     0.000     0.000         0
       Probe      0.998     0.806     0.892      5306
         R2L      0.836     0.083     0.150      1296
         U2R      0.011     1.000     0.021         5

    accuracy                          0.702      7536
   macro avg      0.561     0.572     0.406      7536
weighted avg      0.964     0.702     0.773      7536


--- [フェーズ5 完了] ---

--- [フェーズ6: 既存手法との比較 (論文 4.3.2)] ---

ステップ 6.1: 既存手法用のサンプリング (SMOTE + ENN) を実行中...
サンプリング前のデータ形状: (140981, 122)
サンプリング前のラベル分布 (数値):
0    52458
1    77054
2     8771
3     2584
4      114
Name: count, dtype: int64
ENN (アンダーサンプリング) を有効にして実行します。(時間がかかります)

サンプリング後のデータ形式: <class 'numpy.ndarray'>
サンプリング後のデータ形状: (382764, 122)
サンプリング後のラベル分布 (数値):
0    76936
1    75603
2    76943
3    76280
4    77002
Name: count, dtype: int64

--- 既存手法: ニューラルネットワーク (MLP) の学習・評価 ---
ニューラルネットワーク (MLP) の学習中... (時間がかかる場合があります)
学習完了 (所要時間: 142.4 秒)
未知の攻撃を予測中...

ニューラルネットワーク (MLP) のマイクロ平均 (正解率): 62.42%
 (論文 [表6] ニューラルネットワーク: 0.551)
              precision    recall  f1-score   support

         DoS      1.000     0.296     0.457       929
      Normal      0.000     0.000     0.000         0
       Probe      0.974     0.721     0.828      5306
         R2L      0.972     0.463     0.627      1296
         U2R      0.025     0.800     0.049         5

    accuracy                          0.624      7536
   macro avg      0.594     0.456     0.392      7536
weighted avg      0.976     0.624     0.747      7536


--- 既存手法: サポートベクターマシン (LinearSVC) の学習・評価 ---
サポートベクターマシン (LinearSVC) の学習中... (時間がかかる場合があります)
学習完了 (所要時間: 141.4 秒)
未知の攻撃を予測中...

サポートベクターマシン (LinearSVC) のマイクロ平均 (正解率): 61.21%
 (論文 [表6] サポートベクターマシン: 0.597)
              precision    recall  f1-score   support

         DoS      0.547     0.101     0.171       929
      Normal      0.000     0.000     0.000         0
       Probe      0.982     0.824     0.896      5306
         R2L      0.272     0.110     0.157      1296
         U2R      0.011     0.800     0.022         5

    accuracy                          0.612      7536
   macro avg      0.362     0.367     0.249      7536
weighted avg      0.806     0.612     0.679      7536


--- 既存手法: ランダムフォレスト の学習・評価 ---
ランダムフォレスト の学習中... (時間がかかる場合があります)
学習完了 (所要時間: 19.0 秒)
未知の攻撃を予測中...

ランダムフォレスト のマイクロ平均 (正解率): 53.36%
 (論文 [表6] ランダムフォレスト: 0.572)
              precision    recall  f1-score   support

         DoS      0.018     0.004     0.007       929
      Normal      0.000     0.000     0.000         0
       Probe      0.997     0.757     0.860      5306
         R2L      0.250     0.001     0.002      1296
         U2R      0.667     0.400     0.500         5

    accuracy                          0.534      7536
   macro avg      0.386     0.232     0.274      7536
weighted avg      0.748     0.534     0.607      7536


--- [フェーズ6 完了] ---

--- [全フェーズ 完了] ---